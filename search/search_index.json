{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DTI Wiki","text":"<p>This is the DTI Wiki page dealing with Open Source Softwares used in GNU/Linux Administration and Devops Automation.</p>"},{"location":"about/","title":"Devops Technical Institute - Library","text":"<p>DTI Wiki is an effort to document GNU/Linux Devops process and workflows.</p>"},{"location":"containers/","title":"Containers","text":"<p>Container orchestration,</p> <ul> <li>Docker</li> <li>Kubernetes</li> <li>Kustomize</li> <li>Ambassador Edge Stack</li> </ul>"},{"location":"linux-network-portforwarding/","title":"Basic Port Forwarding","text":"<p>[!WARNING] Don't use this external to one host, when using plain-text protocols (unencrypted). This is not adviced.</p> <p>You have a network service \"pikachu\" that listens on an <code>IP_Addr:port</code> and you need a port forwarding to that same service.</p> <ul> <li>may be on localhost</li> <li>may be from a different network</li> </ul> <p>We can use <code>socat</code> , <code>ncat</code> , <code>goproxy</code>  or <code>go-gost</code> etc.</p>"},{"location":"linux-network-portforwarding/#socat","title":"socat","text":"<p>You can use this command listen on port <code>5050</code> and forward all to port <code>2020</code>.</p> <pre><code>socat tcp-l:5050,fork,reuseaddr tcp:127.0.0.1:2020\n</code></pre> <p>source: <code>http://www.dest-unreach.org/socat/</code></p>"},{"location":"linux-network-portforwarding/#ncat","title":"ncat","text":"<p>This is for NMap <code>Ncat</code> and not <code>nc</code> , you can use the below command to listen on port <code>8080</code> and the forward traffic to port <code>80</code>.</p> <pre><code>ncat -l localhost 8080 --sh-exec \"ncat example.org 80\"\n</code></pre> <p>source: <code>https://nmap.org/ncat/</code></p>"},{"location":"linux-network-portforwarding/#goproxy","title":"goproxy","text":"<p>You can use below command to listen on port <code>1234</code> and forward it to port <code>4567</code> on address <code>10.10.0.1</code> (a local IP Address in your box).</p> <pre><code>proxy tcp -p \":1234\" -T tcp -P \"10.10.0.1:4567\"\n</code></pre> <p>source: <code>https://snail007.host900.com/goproxy/manual/#/</code> and <code>https://github.com/snail007/goproxy/releases</code></p>"},{"location":"linux-network-portforwarding/#go-gost","title":"go-gost","text":"<p>You can use below command to listen on port 1234 and forward it to port 4567 on address <code>10.10.0.1</code> (a local IP Address in your box).</p> <pre><code>gost -L tcp://:1234/1.1.1.1:4567\n</code></pre> <p>source : <code>https://gost.run/en/getting-started/quick-start/</code> and <code>https://github.com/ginuerzh/gost/releases</code></p>"},{"location":"network-process-debug/","title":"Network Process Debugging","text":""},{"location":"network-process-debug/#overview","title":"Overview","text":"<p>The <code>/proc/[pid]/net/</code> directory in Linux provides various network-related information about a specific process with the given Process ID (PID). The files in this directory are helpful for debugging, monitoring, and analyzing the network behavior of a process.</p>"},{"location":"network-process-debug/#structure-of-procpidnet-directory","title":"Structure of <code>/PROC/[PID]/NET/</code> Directory","text":"<p>The <code>/proc/[pid]/net/</code> directory contains several files that provide different types of network-related information for the process with PID <code>[pid]</code>. Some of the common files you may encounter in this directory include:</p> <ol> <li><code>tcp</code>: Displays TCP socket connections related to the process.</li> <li><code>udp</code>: Displays UDP socket connections related to the process.</li> <li><code>tcp6</code>: Displays IPv6 TCP socket connections related to the process.</li> <li><code>udp6</code>: Displays IPv6 UDP socket connections related to the process.</li> <li><code>unix</code>: Displays Unix domain socket connections related to the process.</li> <li><code>raw</code>: Displays raw socket information.</li> <li><code>sctp</code>: Displays SCTP (Stream Control Transmission Protocol) socket connections related to the process.</li> </ol>"},{"location":"network-process-debug/#how-to-use-procpidnet-directory","title":"How to Use <code>/proc/[pid]/net/</code> Directory","text":"<p>Here\u2019s how you can work with the files in <code>/proc/[pid]/net/</code> directory:</p>"},{"location":"network-process-debug/#accessing-network-connections-eg-tcpudp","title":"Accessing Network Connections (e.g., TCP/UDP)","text":"<p>To inspect the TCP and UDP connections associated with a specific process, use the <code>cat</code> command to read the corresponding files.</p> <p>Example:</p> <pre><code>cat /proc/[pid]/net/tcp\ncat /proc/[pid]/net/udp\n</code></pre> <p>Replace <code>[pid]</code> with the actual process ID. The output will display the network connections in a format that includes local and remote IP addresses, ports, connection states, and other information.</p>"},{"location":"network-process-debug/#using-ss-command-with-a-specific-pid","title":"Using <code>ss</code> Command with a Specific PID","text":"<p>The <code>ss</code> (socket stat) command can be used to gather socket-related information, including network connections, for a specific PID.</p> <p>For example:</p> <pre><code>ss -p -n -a | grep [pid]\n</code></pre> <p>This will list Unix domain socket connections, which are used for inter-process communication (IPC) on the same machine.</p>"},{"location":"network-process-debug/#understanding-the-file-format","title":"Understanding the File format","text":"<p>The files in <code>/proc/[pid]/net/</code> are often in a human-readable format but may require some interpretation. For example, the <code>/proc/[pid]/net/tcp</code> file typically displays the following columns:</p> <ul> <li>sl: Socket reference (sequence number).</li> <li>local_address: Local IP address and port.</li> <li>rem_address: Remote IP address and port.</li> <li>st: Connection state (e.g., <code>ESTABLISHED</code>, <code>LISTEN</code>, <code>TIME_WAIT</code>).</li> <li>tx_queue: Transmission queue.</li> <li>rx_queue: Receive queue.</li> <li>tr: Transition state.</li> <li>uid: User ID of the process owning the socket.</li> </ul>"},{"location":"network-process-debug/#monitoring-process-specific-network-traffic","title":"Monitoring Process-Specific Network Traffic","text":"<p>If you want to monitor network traffic by a specific process in real-time, tools like <code>netstat</code>, <code>ss</code>, or <code>lsof</code> can help. For example:</p> <pre><code>netstat -tulnp | grep [pid]\nlsof -i -p [pid]\n</code></pre> <p>This will output the list of all TCP connections associated with process <code>12345</code>. You may need to interpret the values based on the format of the data in the <code>tcp</code> file.</p>"},{"location":"network-process-debug/#useful-notes","title":"Useful Notes","text":"<ul> <li>You need appropriate permissions to access the <code>/proc/[pid]/net/</code> directory, especially for processes you do not own.</li> <li>The files in this directory are snapshots of the state of network sockets, so they represent real-time information but can change frequently.</li> </ul> <p>By using these files and commands, you can get detailed insights into the networking activities of a particular process.</p>"},{"location":"network-process-debug/#finding-ports","title":"Finding ports","text":"<p>To find the ports being used by a specific process through the <code>/proc/[pid]</code> directory, you'll need to look at the network-related files inside <code>/proc/[pid]/net/</code>. Specifically, files like <code>tcp</code>, <code>udp</code>, <code>tcp6</code>, and <code>udp6</code> will provide information on the ports in use by the process, both for TCP/UDP IPv4 and IPv6 connections.</p> <p>Here are the steps to identify the ports used by a process from the <code>/proc/[pid]</code> directory:</p>"},{"location":"network-process-debug/#list-tcpudp-connections","title":"List TCP/UDP connections","text":"<p>The most direct method to find the ports used by a process is to check the <code>/proc/[pid]/net/tcp</code> and <code>/proc/[pid]/net/udp</code> files, which list the TCP and UDP connections, respectively.</p> <pre><code>cat /proc/[pid]/net/tcp\ncat /proc/[pid]/net/udp\n</code></pre> <p>Replace <code>[pid]</code> with the process ID of interest.</p>"},{"location":"network-process-debug/#output-format","title":"Output format","text":"<ul> <li>local_address: Local address (IP address and port) of the connection.</li> <li>rem_address: Remote address (IP address and port) of the connection.</li> <li>st: The state of the connection (for TCP: <code>ESTABLISHED</code>, <code>LISTEN</code>, <code>TIME_WAIT</code>, etc.).</li> <li>uid: The user ID of the process associated with the connection.</li> </ul> <p>Important: The addresses in the <code>local_address</code> and <code>rem_address</code> columns are typically displayed in hexadecimal. You will need to convert the hex values to human-readable IP addresses and ports.</p>"},{"location":"network-process-debug/#interpreting-the-tcp-and-udp-files","title":"Interpreting the <code>tcp</code> and <code>udp</code> Files","text":"<p>Here\u2019s an example of how the lines in <code>/proc/[pid]/net/tcp</code> or <code>/proc/[pid]/net/udp</code> might look:</p> <pre><code>sl  local_address           rem_address           st tx_queue rx_queue tr tm-&gt;when retrnsmt   uid\n1:  0100007F:0050           00000000:0000          01 00000000 00000000 00 00000000 00000000  1000\n2:  0100007F:0051           0100007F:0052          01 00000000 00000000 00 00000000 00000000  1000\n</code></pre> <p>In this example:</p> <ul> <li>local_address (e.g., <code>0100007F:0050</code>) refers to the local address (in hex), and <code>:0050</code> represents port <code>80</code> (<code>0x50</code> in hexadecimal).</li> <li>rem_address (e.g., <code>00000000:0000</code>) is typically the remote address, and <code>:0000</code> often means no established connection for UDP.</li> <li>The st column shows the socket state (<code>01</code> for <code>ESTABLISHED</code> for TCP).</li> </ul>"},{"location":"network-process-debug/#converting-the-local-address","title":"Converting the Local Address:","text":"<p>For the <code>local_address</code> field, the first part is the IP address in hexadecimal, and the second part is the port in hexadecimal. For example:</p> <ul> <li><code>0100007F:0050</code> \u2192 <code>0100007F</code> = <code>127.0.0.1</code> (local IP address), and <code>0050</code> = <code>80</code> (port number).</li> </ul> <p>You can use the following to convert the hex IP to standard dotted decimal notation:</p> <ol> <li>Reverse the byte order (for little-endian representation).</li> <li>Convert each byte to decimal.</li> </ol> <p>For example:</p> <ul> <li><code>0100007F</code> \u2192 <code>7F 00 00 01</code> \u2192 <code>127.0.0.1</code></li> </ul> <p>The port is hexadecimal, so you can convert it similarly:</p> <ul> <li><code>0050</code> \u2192 <code>80</code> (decimal).</li> </ul>"},{"location":"network-process-debug/#other-useful-references","title":"Other Useful References","text":"<p>Using lsof</p> <pre><code>lsof -i -p [pid]\n</code></pre> <p>Using SS</p> <pre><code>ss -tulnp | grep [pid]\n</code></pre>"},{"location":"psy-mcloud/","title":"Psychedelic Magento Cloud","text":"<p>Adobe Commerce Cloud formerly known as Magento Cloud is a Platform as a Service (PaaS) environment for magento 2x family of ecommerce framework. The PaaS is hosted by Adobe on Platform.sh. Customers are given access to the hosted server via restricted SSH acecss. There is only a common SSH user for all user account's created under magento-cloud. The SSH user do not have a dedicated <code>$HOME</code> directory. The \"Psychedelic MCloud\" is a group of custom scripts created to create an overlay over these restrctions and give bash history and other integrations.</p>"},{"location":"psy-mcloud/#source","title":"Source","text":"<p>The Psychedelic Magento Cloud can be found at:</p> <p>Psychedelic Magento Cloud Source</p>"},{"location":"psy-mcloud/#details","title":"Details","text":"<p>Psychedelic MCloud contains customizations for:</p> <ul> <li>bash history</li> <li>tmux integration</li> <li>mysql backups</li> <li>ngrok integration (partial)</li> </ul>"},{"location":"psy-mcloud/#bash","title":"Bash","text":"<p>The bash customization is for enabling bash history, when invoked from the terminal multiplexer (tmux).</p>"},{"location":"psy-mcloud/#tmux","title":"tmux","text":"<p>The tux customization contains the basic <code>tmux.conf</code> file and a custom <code>shell</code> to enable bash overrides.</p> <p>The <code>tmux.conf</code> try to use a custom shell from the file <code>shell</code> from the above bash bash customization. The <code>tmux.conf</code> also have support for mouse support for various versions of tmux found in new-generation and old-generation cloud servers.</p>"},{"location":"psy-mcloud/#initiate-tmux","title":"Initiate tmux","text":"<pre><code>tmux -f var/corra/tmux/tmux.conf new -s corra_devops_01\n</code></pre>"},{"location":"psy-mcloud/#mysql-scripts","title":"MySQL Scripts","text":"<p>There are two mysql customizations in this directory. The <code>myconnect</code> is used to connect to mysql by directly reading <code>app/etc/env.php</code>. Also <code>mydbdump</code> is a mysql backup script.</p>"},{"location":"psy-mcloud/#ngrok","title":"ngrok","text":"<p>This is used for media sync using ngrok</p>"},{"location":"ssh-tunnels/","title":"SSH Tunneling","text":"<p>OpenSSH support some tunneling features, which helps achieve security use cases such as remote web service access without exposing ports on the internet, accessing servers behind NAT, exposing local ports to the internet.</p>"},{"location":"ssh-tunnels/#what-is-ssh-tunneling","title":"What is SSH tunneling?","text":"<p>SSH tunneling is a method to transport additional data streams within an existing SSH session. SSH tunneling helps achieve security use cases such as remote web service access without exposing port on the internet, accessing server behind NAT, exposing local port to the internet.</p>"},{"location":"ssh-tunnels/#access-a-remote-service-securely-over-ssh-tunnel","title":"Access a remote service securely over SSH Tunnel","text":"<p>There is a service running on remote server and it is not exposed to internet. Now you need to access this service without exposing the service to internet. SSH Tunnel can help in this situation. For security reasons we should only bind services to local interfaces. Or if really required bind it to interface connected to private network. Binding the services on internet interfaces is not recommended.</p>"},{"location":"ssh-tunnels/#scenario","title":"Scenario","text":"<p>We have a production cloud server in AWS and it runs a web-server on port 9191 and the port 9191 is not accessible from internet.</p> <p>We also have a dev cloud server in Rackspace and we need to download a file named \"/dynamically_generate_pdf_files.tar.bz2\" from the AWS production web-server (on port 9191) to the Rackspace dev server.</p> <p>But the problem is that the port 9191 of the AWS production web-server is not accessible from internet, so Rackspace dev server cannot directly download the file.</p> <p>Now, the only connection option between AWS production web-server and Rackspace dev server is an SSH connection.</p>"},{"location":"ssh-tunnels/#procedure","title":"Procedure","text":"<p>Connect to the AWS production web-server over SSH</p> <p>start the web-server service on the AWS production web-server</p> <p>Lets use python one-liner web-server:</p> <pre><code>python3 -m http.server 9191\n</code></pre> <p>Now, let the python one-liner web-server run for the entire duration of the procedure.</p> <p>Connect to the Rackspace dev server over SSH</p> <p>then open a SSH connection to AWS production web-server tunneling to the port 9191 on AWS production web-server from the Rackspace dev server.</p> <p><pre><code>ssh -i /path/to/rsa_private_key -N -L 9191:127.0.0.1:9191 user@AWS_production_web-server\n</code></pre> Then do:</p> <pre><code>curl http://127.0.0.1:9191/\n</code></pre>"},{"location":"containers/docker/","title":"Docker","text":"<p>These are the wiki pages created under Docker</p>"},{"location":"containers/docker/#contents","title":"Contents","text":"<ol> <li>Container Init Script</li> <li>Caddy Server</li> </ol>"},{"location":"containers/docker/caddy-container/","title":"Caddy Container","text":"<p>Using a Caddy Server as a reverse proxy to route traffic to adminer.</p>"},{"location":"containers/docker/caddy-container/#caddyfile","title":"Caddyfile","text":"<p>Below is the Caddyfile v2</p> <pre><code>your-name.domain.com\n\nencode gzip\nreverse_proxy /sql adminer:8080\ntls your-email@domain.com\n</code></pre>"},{"location":"containers/docker/caddy-container/#docker-compose","title":"Docker Compose","text":"<p>Below is the <code>docker-compose.yml</code> file for Caddy Server.</p> <pre><code>version: \"3.2\"\n\nservices:\n  sql1:\n    container_name: sql1\n    image: mcr.microsoft.com/mssql/server:2022-latest\n    tty: true\n    ports:\n      - \"135:135\"\n      - \"1431:1431\"\n      - \"1433:1433\"\n      - \"1434:1434\"\n    restart: always\n    environment:\n      MSSQL_SA_PASSWORD: fake1234567890xyz\n      SA_PASSWORD: fake1234567890xyz\n      ACCEPT_EULA: \"Y\"\n    volumes:\n      - /home/user/service/dumps:/dumps\n      - /home/user/service/db/data:/var/opt/mssql/data\n\n  caddy:\n    image: caddy:2.6.2-alpine\n    container_name: caddy\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n      - \"443:443/udp\"\n    volumes:\n      - /home/user/service/caddy/Caddyfile:/etc/caddy/Caddyfile\n\n  adminer:\n    container_name: adminer\n    image: adminer:latest\n    ports:\n      - \"8080:8080\"\n    links:\n      - sql1\n    depends_on:\n      - sql1\n    restart: always\n</code></pre>"},{"location":"containers/docker/container-init/","title":"Container Init","text":"<p>At times, we think if only this container acted a little different that its normal.</p> <p>say for example:</p> <ul> <li>we need to change the default user defined in <code>dockerfile</code> but at the same time we don't want to rebuild the dockerimage.</li> <li>install new packages in a docker image, yet we don't want to build a new image using the source of the original docker image.</li> <li>sometimes when you are lazy and you want to directly manipulate a docker image</li> </ul>"},{"location":"containers/docker/container-init/#the-script","title":"The Script","text":"<p>Then you may need \"con-init\" or <code>coninit.sh</code> a.k.a \"Container Init\"</p> <p>This is a <code>coninit.sh</code> for alpine linux based containers.</p> <pre><code>#!/bin/bash\n\nCUID=1000\nCGID=1000\nUSERNAME=anish\n\n#install dependencies\napk update\napk add shadow sudo bash curl yarn jq\n\n#Create User and Groups and Sudo Access\ngroupadd -g ${CGID} ${USERNAME}\nuseradd ${USERNAME} -u ${CUID} -g ${CGID} -m -s /bin/bash\nusermod -a -G wheel ${USERNAME}\necho \"${USERNAME} ALL=(ALL) NOPASSWD:ALL\" &gt;&gt; /etc/sudoers.d/${USERNAME}\n\n#Run infinitely\ntail -f /dev/null\n</code></pre> <p>If we are using a debian/ubuntu container then the above (for alpine) won't work as expected. So in case of Debian based containers use below.</p> <pre><code>#!/bin/bash\n\nCUID=1000\nCGID=1000\nUSERNAME=anish\n\n#install dependencies\napt update\napt install -y passwd sudo bash curl jq vim-tiny git\n\n#Create User and Groups and Sudo Access\ngroupadd -g ${CGID} ${USERNAME}\nuseradd ${USERNAME} -u ${CUID} -g ${CGID} -m -s /bin/bash\nUID_MAX=500000000 usermod -a -G adm,sudo ${USERNAME}\necho \"${USERNAME} ALL=(ALL) NOPASSWD:ALL\" &gt;&gt;/etc/sudoers.d/${USERNAME}\n\n#Run infinitely\ntail -f /dev/null\n</code></pre>"},{"location":"containers/docker/container-init/#the-compose-file","title":"The Compose file","text":"<p>Now to use this <code>coninit.sh</code> we wil employ a <code>docker-compose.yml</code> file as below:</p> <pre><code>version: '3.8'\nservices:\n  node-dev:\n    image: node:16.16.0-slim\n    container_name: node-dev\n    working_dir: /srv\n    environment:\n      - VAR1=\"Foo\"\n      - VAR2=\"Bar\"\n    volumes:\n      - ./con-init.sh:/root/con-init.sh\n      - ./app:/srv\n    command: sh /root/con-init.sh\n</code></pre> <p>Create a empty directory named \"app\" in the same directory which houses <code>docker-compose.yml</code> file.</p> <p>you can put the code files in the newly created \"app\" directory.</p> <p>Then do:</p> <pre><code>docker-compose up -d\n</code></pre> <p>now a new container named <code>node-dev</code> with start using the <code>node:16.16.0-slim</code> image with the changes we added in the <code>coninit.sh</code> file.</p> <p>Now lets connect to the new container, assuming we created the user as <code>anish</code> in the <code>coninit.sh</code> file. If you used a different user replace <code>anish</code> with the username you used in the below command.</p> <pre><code>docker-compose exec -u anish -it node-dev /bin/bash\n</code></pre>"},{"location":"containers/kubernetes/","title":"Kubernetes","text":"<p>These are the wiki pages created under Kubernetes</p>"},{"location":"containers/kubernetes/#contents","title":"Contents","text":""},{"location":"containers/kubernetes/#basic-cheatsheets","title":"Basic Cheatsheets","text":"<ol> <li>Kubectl Basic Cheatsheet - Part Uno</li> <li>Kubectl Basic Cheatsheet - Part Duo</li> </ol>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-1/","title":"Kubectl Basic Cheatsheet - Part Uno","text":"<p>Kubectl is like the swiss army knife when dealing with kubernetes cluster.</p> <p>These are some basic hacks, which will be useful to someone.</p>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-1/#dealing-with-jsonpath","title":"Dealing with jsonpath","text":"<p>JSONPath template is composed of JSONPath expressions enclosed by {}. We can use JSONPath expressions to filter on specific fields from kubectl outputs.</p>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-1/#good-reads","title":"Good Reads","text":"<ul> <li>https://downey.io/notes/dev/kubectl-jsonpath-new-lines/</li> <li>https://gist.github.com/so0k/42313dbb3b547a0f51a547bb968696ba</li> <li>https://kubernetes.io/docs/reference/kubectl/jsonpath/</li> <li>https://unofficial-kubernetes.readthedocs.io/en/latest/user-guide/jsonpath/</li> </ul>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-1/#printing-the-names-of-kubernetes-deployments","title":"Printing the names of kubernetes deployments","text":"<pre><code>kubectl get -n kube-system deploy -o jsonpath='{range .items[*]}{.metadata.name}{\"\\n\"}{end}'\n</code></pre> <p>See the sample output</p> <pre><code>$ kubectl get -n newrelic deploy -o jsonpath='{range .items[*]}{.metadata.name}{\"\\n\"}{end}'\nkelvin\nnri-bundle-kube-state-metrics\nnri-bundle-nri-kube-events\nnri-bundle-nri-metadata-injection\nnri-bundle-nrk8s-ksm\nvizier-cloud-connector\nvizier-query-broker\n</code></pre>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-1/#printing-the-ip-addresses-of-the-all-pods-in-newrelic-namespace","title":"Printing the IP Addresses of the all pods in newrelic namespace","text":"<pre><code>kubectl get pods -n newrelic -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}'\n</code></pre> <p>See the sample output</p> <pre><code>$ kubectl get pods -n newrelic -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}'\n172.16.0.179\n172.16.1.17\n172.16.1.198\n172.16.1.61\n172.16.0.183\n172.16.0.187\n172.16.1.132\n172.16.1.178\n172.16.1.11\n172.16.0.178\n172.16.1.167\n172.16.1.214\n172.16.1.161\n172.16.0.81\n172.16.1.209\n172.16.1.61\n172.16.0.183\n172.16.1.198\n172.16.1.102\n</code></pre> <p>You can use two fields and format it to your liking using whitespace as well.</p> <pre><code>kubectl get pods -n newrelic -o jsonpath='{range .items[*]}{.metadata.namespace}{\"/\"}{.metadata.name}{\",\"}{.status.podIP}{\"\\n\"}{end}'\n</code></pre> <p>See the sample output</p> <pre><code>$ kubectl get pods -n newrelic -o jsonpath='{range .items[*]}{.metadata.namespace}{\"/\"}{.metadata.name}{\",\"}{.status.podIP}{\"\\n\"}{end}'\nnewrelic/kelvin-54b954889c-4zsz5,172.16.0.179\nnewrelic/nri-bundle-kube-state-metrics-778f8d7756-6tgzg,172.16.1.17\nnewrelic/nri-bundle-newrelic-logging-9bctl,172.16.1.198\nnewrelic/nri-bundle-newrelic-logging-splhw,172.16.1.61\nnewrelic/nri-bundle-newrelic-logging-tfl7r,172.16.0.183\nnewrelic/nri-bundle-newrelic-prometheus-agent-0,172.16.0.187\nnewrelic/nri-bundle-nri-kube-events-695cc855d4-jtdtk,172.16.1.132\nnewrelic/nri-bundle-nri-metadata-injection-7bfddbc55d-khxrt,172.16.1.178\nnewrelic/nri-bundle-nrk8s-ksm-9bf8fbf54-fpp29,172.16.1.11\nnewrelic/nri-bundle-nrk8s-kubelet-22plc,172.16.0.178\nnewrelic/nri-bundle-nrk8s-kubelet-qzhhs,172.16.1.167\nnewrelic/nri-bundle-nrk8s-kubelet-vpmbq,172.16.1.214\nnewrelic/pl-nats-0,172.16.1.161\nnewrelic/vizier-cloud-connector-5d454b78f6-wq2v8,172.16.0.81\nnewrelic/vizier-metadata-0,172.16.1.209\nnewrelic/vizier-pem-6ctzn,172.16.1.61\nnewrelic/vizier-pem-vgbq5,172.16.0.183\nnewrelic/vizier-pem-wfbwk,172.16.1.198\nnewrelic/vizier-query-broker-7f57fbfc6d-5qckt,172.16.1.102\n</code></pre>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-2/","title":"Kubectl Basic Cheatsheet - Part Duo","text":"<p>Continuation of https://dti-wiki.github.io/containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-1/</p>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-2/#format-kubectl-output-as-rows-and-columns","title":"Format Kubectl output as rows and columns","text":""},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-2/#formatting-output-as-rows","title":"Formatting Output as Rows","text":"<pre><code>kubectl get pods -n newrelic -o jsonpath='{range .items[*]}{\"pod: \"}{.metadata.name}{\"\\n\"}{range .spec.containers[*]}{\"\\tname: \"}{.name}{\"\\n\\timage: \"}{.image}{\"\\n\"}{end}'\n</code></pre> <p>This should give output as below:</p> <pre><code>pod: kelvin-54b954889c-4zsz5\n        name: app\n        image: gcr.io/pixie-oss/pixie-prod/vizier/kelvin_image:0.13.4\npod: nri-bundle-kube-state-metrics-778f8d7756-6tgzg\n        name: kube-state-metrics\n        image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.6.0\npod: nri-bundle-newrelic-logging-9bctl\n        name: newrelic-logging\n        image: newrelic/newrelic-fluentbit-output:1.14.0\npod: nri-bundle-newrelic-logging-splhw\n        name: newrelic-logging\n        image: newrelic/newrelic-fluentbit-output:1.14.0\npod: nri-bundle-newrelic-logging-tfl7r\n        name: newrelic-logging\n        image: newrelic/newrelic-fluentbit-output:1.14.0\npod: nri-bundle-newrelic-prometheus-agent-0\n        name: prometheus\n        image: quay.io/prometheus/prometheus:v2.37.3\npod: nri-bundle-nri-kube-events-695cc855d4-jtdtk\n        name: kube-events\n        image: newrelic/nri-kube-events:1.9.1\n        name: forwarder\n        image: newrelic/k8s-events-forwarder:1.33.1\npod: nri-bundle-nri-metadata-injection-7bfddbc55d-khxrt\n        name: nri-metadata-injection\n        image: newrelic/k8s-metadata-injection:1.7.5\npod: nri-bundle-nrk8s-ksm-9bf8fbf54-fpp29\n        name: ksm\n        image: newrelic/nri-kubernetes:3.6.0\n        name: forwarder\n        image: newrelic/k8s-events-forwarder:1.33.2\npod: nri-bundle-nrk8s-kubelet-22plc\n        name: kubelet\n        image: newrelic/nri-kubernetes:3.6.0\n        name: agent\n        image: newrelic/infrastructure-bundle:2.8.34\npod: nri-bundle-nrk8s-kubelet-qzhhs\n        name: kubelet\n        image: newrelic/nri-kubernetes:3.6.0\n        name: agent\n        image: newrelic/infrastructure-bundle:2.8.34\npod: nri-bundle-nrk8s-kubelet-vpmbq\n        name: kubelet\n        image: newrelic/nri-kubernetes:3.6.0\n        name: agent\n        image: newrelic/infrastructure-bundle:2.8.34\npod: pl-nats-0\n        name: pl-nats\n        image: gcr.io/pixie-oss/pixie-prod/vizier-deps/nats:multiarch-2.8.4-alpine3.15@sha256:988010f74b61749cfb82c28b50b47d26d0b972860ce6e9325a5afcde97713da2\npod: vizier-cloud-connector-5d454b78f6-wq2v8\n        name: app\n        image: gcr.io/pixie-oss/pixie-prod/vizier/cloud_connector_server_image:0.13.4\npod: vizier-metadata-0\n        name: app\n        image: gcr.io/pixie-oss/pixie-prod/vizier/metadata_server_image:0.13.4\npod: vizier-pem-6ctzn\n        name: pem\n        image: gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.13.4\npod: vizier-pem-vgbq5\n        name: pem\n        image: gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.13.4\npod: vizier-pem-wfbwk\n        name: pem\n        image: gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.13.4\npod: vizier-query-broker-7f57fbfc6d-5qckt\n        name: app\n        image: gcr.io/pixie-oss/pixie-prod/vizier/query_broker_server_image:0.13.4\n</code></pre>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-2/#formatting-output-as-columns","title":"Formatting Output as Columns","text":"<pre><code>kubectl get pod -n newrelic -o=\"custom-columns=PODS:.metadata.name,NAME:.spec.containers[*].name,IMAGE:.spec.containers[*].image,INIT-CONTAINERS:.spec.initContainers[*].name,CONTAINERS:.spec.containers[*].name\"\n</code></pre> <p>This should give output as below:</p> <pre><code>PODS                                                 NAME                     IMAGE                                                                                                                                             INIT-CONTAINERS    CONTAINERS\nkelvin-54b954889c-4zsz5                              app                      gcr.io/pixie-oss/pixie-prod/vizier/kelvin_image:0.13.4                                                                                            cc-wait,qb-wait    app\nnri-bundle-kube-state-metrics-778f8d7756-6tgzg       kube-state-metrics       registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.6.0                                                                                      &lt;none&gt;             kube-state-metrics\nnri-bundle-newrelic-logging-9bctl                    newrelic-logging         newrelic/newrelic-fluentbit-output:1.14.0                                                                                                         &lt;none&gt;             newrelic-logging\nnri-bundle-newrelic-logging-splhw                    newrelic-logging         newrelic/newrelic-fluentbit-output:1.14.0                                                                                                         &lt;none&gt;             newrelic-logging\nnri-bundle-newrelic-logging-tfl7r                    newrelic-logging         newrelic/newrelic-fluentbit-output:1.14.0                                                                                                         &lt;none&gt;             newrelic-logging\nnri-bundle-newrelic-prometheus-agent-0               prometheus               quay.io/prometheus/prometheus:v2.37.3                                                                                                             configurator       prometheus\nnri-bundle-nri-kube-events-695cc855d4-jtdtk          kube-events,forwarder    newrelic/nri-kube-events:1.9.1,newrelic/k8s-events-forwarder:1.33.1                                                                               &lt;none&gt;             kube-events,forwarder\nnri-bundle-nri-metadata-injection-7bfddbc55d-khxrt   nri-metadata-injection   newrelic/k8s-metadata-injection:1.7.5                                                                                                             &lt;none&gt;             nri-metadata-injection\nnri-bundle-nrk8s-ksm-9bf8fbf54-fpp29                 ksm,forwarder            newrelic/nri-kubernetes:3.6.0,newrelic/k8s-events-forwarder:1.33.2                                                                                &lt;none&gt;             ksm,forwarder\nnri-bundle-nrk8s-kubelet-22plc                       kubelet,agent            newrelic/nri-kubernetes:3.6.0,newrelic/infrastructure-bundle:2.8.34                                                                               &lt;none&gt;             kubelet,agent\nnri-bundle-nrk8s-kubelet-qzhhs                       kubelet,agent            newrelic/nri-kubernetes:3.6.0,newrelic/infrastructure-bundle:2.8.34                                                                               &lt;none&gt;             kubelet,agent\nnri-bundle-nrk8s-kubelet-vpmbq                       kubelet,agent            newrelic/nri-kubernetes:3.6.0,newrelic/infrastructure-bundle:2.8.34                                                                               &lt;none&gt;             kubelet,agent\npl-nats-0                                            pl-nats                  gcr.io/pixie-oss/pixie-prod/vizier-deps/nats:multiarch-2.8.4-alpine3.15@sha256:988010f74b61749cfb82c28b50b47d26d0b972860ce6e9325a5afcde97713da2   &lt;none&gt;             pl-nats\nvizier-cloud-connector-5d454b78f6-wq2v8              app                      gcr.io/pixie-oss/pixie-prod/vizier/cloud_connector_server_image:0.13.4                                                                            nats-wait          app\nvizier-metadata-0                                    app                      gcr.io/pixie-oss/pixie-prod/vizier/metadata_server_image:0.13.4                                                                                   nats-wait          app\nvizier-pem-6ctzn                                     pem                      gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.13.4                                                                                               qb-wait            pem\nvizier-pem-vgbq5                                     pem                      gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.13.4                                                                                               qb-wait            pem\nvizier-pem-wfbwk                                     pem                      gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.13.4                                                                                               qb-wait            pem\nvizier-query-broker-7f57fbfc6d-5qckt                 app                      gcr.io/pixie-oss/pixie-prod/vizier/query_broker_server_image:0.13.4                                                                               cc-wait,mds-wait   app\n</code></pre>"},{"location":"containers/kubernetes/kubectl/cheatsheets/kubectl-basic-part-2/#formatting-output-as-lines","title":"Formatting Output as Lines","text":"<pre><code>kubectl get pods/nri-bundle-nri-kube-events-695cc855d4-jtdtk -n newrelic -o jsonpath='{range .spec.containers[*]}{.name}{\"\\n\"}{end}'\n</code></pre> <p>This should give output as below:</p> <pre><code>kube-events\nforwarder\n</code></pre>"},{"location":"snippets/cloud-cron-disable/","title":"Disable Cron on Magento Enterprise Cloud","text":"<p>Usually crons are by default enabled in the magento configuration. If you have to disable the magento cloud crons.</p> <p>Please modify <code>app/etc/env.php</code> and add <code>'enabled' =&gt; 0,</code> under \"cron\" array as below.</p> <pre><code>  'cron' =&gt;\n  array (\n    'enabled' =&gt; 0,\n  ),\n</code></pre> <p>If the <code>env.php</code> is <code>square-brackets</code> then use below format:</p> <pre><code>    'cron' =&gt; [\n        'enabled' =&gt; 0\n    ]\n</code></pre> <p>Monitor the cron logs :</p> <pre><code>tail -f $HOME/var/log/cron.log\n</code></pre>"},{"location":"snippets/cloud-db-auth/","title":"Magento 2x Cloud DB Authentication","text":""},{"location":"snippets/cloud-db-auth/#set-time","title":"Set Time","text":"<pre><code>BKPTIM=$(date +\"%Y-%m-%d_%H-%M-%S\")\n</code></pre>"},{"location":"snippets/cloud-db-auth/#ticket-number","title":"Ticket Number","text":"<p>Optionally set ticket number if required.</p> <pre><code>TKT=\"JIRA-123\"\n</code></pre>"},{"location":"snippets/cloud-db-auth/#set-authentication-variables","title":"Set Authentication variables:","text":"<pre><code>export DB_NAME=$(grep [\\']db[\\'] -A 20 app/etc/env.php | grep dbname | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/['][,]//\");\n\nexport MYSQL_HOST=$(grep [\\']db[\\'] -A 20 app/etc/env.php | grep host | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/['][,]//\");\n\nexport DB_USER=$(grep [\\']db[\\'] -A 20 app/etc/env.php | grep username | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/['][,]//\");\n\nexport MYSQL_PWD=$(grep [\\']db[\\'] -A 20 app/etc/env.php | grep password | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/[']$//\" | sed \"s/['][,]//\");\n</code></pre>"},{"location":"snippets/cloud-db-auth/#connect-to-mysql-with-above-set-authentication-variables","title":"Connect to MySQL with above set authentication variables.","text":"<pre><code>mysql -h $MYSQL_HOST -u $DB_USER --password=$MYSQL_PWD $DB_NAME -A\n</code></pre>"},{"location":"snippets/cloud-db-auth/#database-dump","title":"Database Dump","text":"<pre><code>mysqldump -h $MYSQL_HOST -u $DB_USER --password=$MYSQL_PWD $DB_NAME --opt --single-transaction --skip-lock-tables | sed -e 's/DEFINER[ ]*=[ ]*[^*]*\\*/\\*/' | gzip &gt; var/backups/$DB_NAME.${BKPTIM}.sql.gz\n</code></pre> <p>If you want to add the ticket name to the dump as well.</p> <pre><code>mysqldump -h $MYSQL_HOST -u $DB_USER --password=$MYSQL_PWD $DB_NAME --opt --single-transaction --skip-lock-tables | sed -e 's/DEFINER[ ]*=[ ]*[^*]*\\*/\\*/' | gzip &gt; var/backups/$TKT.$DB_NAME.${BKPTIM}.sql.gz\n</code></pre>"},{"location":"snippets/cloud-db-auth/#other-useful-flags","title":"Other Useful Flags","text":"<p>In certian MySQL servers from verion 5.7 and above, we may get permission denied for some nonsensical privileges.</p> <p>you can use the below mysql CLI flags to spuress those errors.</p> <pre><code>--set-gtid-purged=OFF --no-tablespaces\n</code></pre>"},{"location":"snippets/cloud-elasticsearch-management/","title":"Magento Cloud Elasticsearch Management","text":"<p>The elasticsearch in magento cloud maight require manual maintenanace from time to time. This document list the useful commands to manage the magento cloud elasticsearch instance using CURL http client.</p>"},{"location":"snippets/cloud-elasticsearch-management/#why","title":"Why?","text":"<p>There can be several potential causes. One cause is the Elasticsearch instance running out of disk space. Another cause is duplicated indices.</p>"},{"location":"snippets/cloud-elasticsearch-management/#word-of-advice","title":"Word of advice!","text":"<ol> <li>Create a fresh mysql dump before following these steps</li> <li>Perform this operations outside of business hours</li> <li>On production environments enable maintenanace mode if possible</li> <li>On production environments disble the magento cron jobs till this activity is completed.</li> </ol>"},{"location":"snippets/cloud-elasticsearch-management/#procedure","title":"Procedure","text":""},{"location":"snippets/cloud-elasticsearch-management/#list-indices","title":"List Indices","text":"<p>List the indices on the elasticsearch instance</p> <pre><code>curl -s -X GET localhost:9200/_cat/indices?v\n</code></pre> <p>This should give something lie this:</p> <pre><code>health status index                        uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   magento2_stg_product_16_v3   ro_35-TIQ5KT9H4ggVOwZw   3   2          0            0        2kb           705b\ngreen  open   magento2_stg_product_20_v94  MPZqxSLQQweP_YwjuIeTWg   3   2         19            4    955.9kb        318.6kb\ngreen  open   magento2_stg_product_18_v208 X7FehtL5RROo_crbnHYCxw   3   2         19            0    504.1kb          168kb\ngreen  open   magento2_stg_product_17_v4   lb-6wI_PTr-9hKVWWIQYjA   3   2          0            0        2kb           693b\ngreen  open   magento2_stg_product_6_v109  5ibsu0JmT9uOAS98bDS3Tg   3   2         61            0    201.3kb         64.6kb\ngreen  open   magento2_stg_product_1_v3552 fWMK8iSzRjeub_z58sT5gg   3   2        552           11     25.8mb          8.4mb\ngreen  open   magento2_stg_product_15_v125 HwztB4diTH2fQRGWwKS14A   3   2         21            3      1.6mb        547.8kb\ngreen  open   magento2_stg_product_9_v179  paVM9hHvT32ZG9jDNipNRg   3   2          0            0      1.8kb           624b\ngreen  open   magento2_stg_product_14_v498 _W2lSyEsQdWChM6kMro6Xw   3   2         21            0      1.1mb        398.2kb\ngreen  open   magento2_stg_product_5_v1094 2QfuKR42Q8q73oIsCJmNow   3   2        447            0     16.4mb          5.2mb\ngreen  open   magento2_product_1_v1        3irjvym7T5ycPgeQV0pOcg   3   2          0            0      2.2kb           783b\n</code></pre>"},{"location":"snippets/cloud-elasticsearch-management/#delete-indices","title":"Delete Indices","text":"<pre><code>curl -XDELETE localhost:9200/[your_index_name_here]\n</code></pre> <p>Then do a full reindexing.</p>"},{"location":"snippets/cloud-elasticsearch-management/#source","title":"Source:","text":"<ul> <li>https://support.magento.com/hc/en-us/articles/360039837952-Elasticsearch-Index-Status-is-yellow-or-red-</li> <li>https://experienceleague.adobe.com/docs/commerce-knowledge-base/kb/troubleshooting/elasticsearch/elasticsearch-index-status-is-yellow-or-red.html?lang=en</li> </ul>"},{"location":"snippets/cloud-rabbitmq-management/","title":"RabbitMQ Management","text":"<p>To get the RabbitMQ connection credentials, Refer:</p> <p>URL: https://experienceleague.adobe.com/docs/commerce-cloud-service/user-guide/configure/service/services-yaml.html?lang=en</p> <p>or execute below comand</p> <pre><code>echo $MAGENTO_CLOUD_RELATIONSHIPS | base64 -d | json_pp\n</code></pre> <p>Which will provide you mething like:</p> <pre><code>   \"rabbitmq\" : [\n      {\n         \"username\" : \"mcloudprojectID_stg2\",\n         \"vhost\" : \"mcloudprojectID_stg2\",\n         \"port\" : \"5672\",\n         \"host\" : \"localhost\",\n         \"scheme\" : \"amqp\",\n         \"password\" : \"Password_of_your_RabbitMQ\"\n      }\n   ],\n</code></pre> <p>On non-magento-cloud instances use:</p> <pre><code>grep amqp -A 7 app/etc/env.php\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#set-variables","title":"Set Variables","text":"<p>Set the path of your magrnto <code>env.php</code> file.</p> <pre><code>export ENVFILE=app/etc/env.php\n</code></pre> <p>Set the below variables for RabbitMQ conectivity.</p> <pre><code>export RABBITHOST=$(grep amqp -A 7 ${ENVFILE} | grep host | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/['][,]//\");\n\nexport RABBITUSER=$(grep amqp -A 7 ${ENVFILE} | grep user | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/['][,]//\");\n\nexport RABBITPASS=$(grep amqp -A 7 ${ENVFILE} | grep password | head -n1 | sed \"s/.*[=][&gt;][ ]*[']//\" | sed \"s/['][,]//\");\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#connect-to-rabbitmq-in-mcloud","title":"Connect to RabbitMQ in MCloud","text":""},{"location":"snippets/cloud-rabbitmq-management/#list-exchanges","title":"List Exchanges","text":"<pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} list exchanges\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#list-vhosts","title":"List Vhosts","text":"<pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} list vhosts\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#list-queues","title":"List Queues","text":"<pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} list queues\n</code></pre> <p>Specify Columns</p> <pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} list queues vhost name node messages message_stats.publish_details.rate\n</code></pre> <p>Long Listing</p> <pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} list queues -f long -d 3 list queues\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#list-bindings","title":"List Bindings","text":"<pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} list bindings\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#additional-info","title":"Additional Info.","text":"<p>In the above senario, the admin port is running on TCP port 80/HTTP. But if in your case the rabbitMQ admin port is running on TCP port 443/HTTPS then add below option:</p> <pre><code>--port 443 --ssl\n</code></pre> <p>for ex:</p> <pre><code>rabbitmqadmin -u ${RABBITUSER} -p ${RABBITPASS} -H ${RABBITHOST} --port 443 --ssl list queues\n</code></pre>"},{"location":"snippets/cloud-rabbitmq-management/#references","title":"References","text":"<p>URL's used:</p> <ul> <li>https://www.rabbitmq.com/docs/management-cli</li> </ul>"},{"location":"snippets/curl-stats/","title":"Collect HTTP Stats using cURL","text":"<p>cURL supports formatted output for the details of the request (see the cURL manpage for details, under <code>-w, \u2013write-out &lt;format&gt;</code> ). Lets try to collect the time statistics of HTTP connection. Times below are in seconds.</p>"},{"location":"snippets/curl-stats/#prerequisite","title":"Prerequisite","text":"<p>we need a http-delay statistics file.</p> <p>Lets create a directory and file for this requirement.</p> <pre><code>mkdir -vp ~/projects/dti-wiki/http-delay\n</code></pre> <p><pre><code>touch ~/projects/dti-wiki/http-delay/curl-stats.txt\n</code></pre> Lets create the contents for the statistics file.</p> <p>paste the below content to: <code>~/projects/dti-wiki/http-delay/curl-stats.txt</code></p> <pre><code>     time_namelookup:  %{time_namelookup}s\\n\n        time_connect:  %{time_connect}s\\n\n     time_appconnect:  %{time_appconnect}s\\n\n    time_pretransfer:  %{time_pretransfer}s\\n\n       time_redirect:  %{time_redirect}s\\n\n  time_starttransfer:  %{time_starttransfer}s\\n\n                     ----------\\n\n          time_total:  %{time_total}s\\n\n</code></pre>"},{"location":"snippets/curl-stats/#execution","title":"Execution","text":"<p>We can execute the cURL as below to collect the HTTP statistics.</p> <pre><code>curl -w \"@${HOME}/projects/dti-wiki/http-delay/curl-stats.txt\" -o /dev/null -s \"http://wordpress.com/\"\n</code></pre> <p>We can create this cURL command as a bash script.</p> <p>create a file : <code>~/bin/httpstats</code> with below content.</p> <pre><code>#!/bin/bash\n\ncurl -w @- -o /dev/null -s \"$@\" &lt;&lt;'EOF'\n    time_namelookup:  %{time_namelookup}\\n\n       time_connect:  %{time_connect}\\n\n    time_appconnect:  %{time_appconnect}\\n\n   time_pretransfer:  %{time_pretransfer}\\n\n      time_redirect:  %{time_redirect}\\n\n time_starttransfer:  %{time_starttransfer}\\n\n                    ----------\\n\n         time_total:  %{time_total}\\n\nEOF\n</code></pre> <p>Now lets give execute permissions for <code>~/bin/httpstats</code> file:</p> <pre><code>chmod +x ~/bin/httpstats\n</code></pre> <p>Then we can execute the command like</p> <pre><code>httpstats http://wordpress.org\n</code></pre>"},{"location":"snippets/curl-stats/#other-useful-oneliners","title":"Other useful oneliners","text":"<p>Collect <code>total time</code> taken:</p> <pre><code>curl -o /dev/null -s -w 'Total: %{time_total}s\\n'  https://www.google.com\n</code></pre> <pre><code>curl -o /dev/null -s -w 'Establish Connection: %{time_connect}s\\nTTFB: %{time_starttransfer}s\\nTotal: %{time_total}s\\n'  https://www.google.com\n</code></pre>"},{"location":"snippets/custom-home-dir-ubuntu-firefox-err/","title":"Snap Firefox cannot create user data directory","text":"<p>This issue is only reported on firefox installed from snap. And this issue will only present itself if the user is having a custom $HOME directory.</p> <p>Usually snap is configuring Ubuntu AppArmor with DEFAULT HOME DIRECTORY path for ex: <code>/home/some_username</code> .</p> <p>But in your case if you are using custom AD integration in your Ubuntu then you may be having custom home directory like <code>/home/local/AD_DOMAIN/username</code> .</p>"},{"location":"snippets/custom-home-dir-ubuntu-firefox-err/#possibile-fix","title":"Possibile Fix","text":"<p>If you use domain with realm, so our path home is not <code>/home</code> , and instead home path like <code>/home/MYDOMAINCOMPANY/</code>. </p> <p>You need to edit your <code>/etc/apparmor.d/tunables/home.d/ubuntu</code> and add below line:</p> <pre><code>@{HOMEDIRS}+=/home/MYDOMAINCOMPANY/\n</code></pre> <p>After save, you need to restart some services:</p> <pre><code>sudo systemctl restart apparmor.service snapd.apparmor.service snapd.service snapd.socket\n</code></pre> <p>This should fix the issues with firefox.</p>"},{"location":"snippets/magento-indexing/","title":"Magento Indexing","text":"<p>Indexing is how Magento transforms data such as products and categories, to improve the performance of your storefront. As data changes, the transformed data must be updated or reindexed. To optimize storefront performance, Magento accumulates data into special tables using indexers.</p> <p>For example, if you change the price of an item from 3.99. Magento must reindex the price change to display it on your storefront.</p>"},{"location":"snippets/magento-indexing/#view-a-list-of-indexers","title":"View a list of indexers","text":"<p>To view a list of all indexers:</p> <pre><code>bin/magento indexer:info\n</code></pre> <p>The list displays as follows:</p> <pre><code>design_config_grid                       Design Config Grid\ncustomer_grid                            Customer Grid\ncatalog_category_product                 Category Products\ncatalog_product_category                 Product Categories\ncatalogrule_rule                         Catalog Rule Product\ncatalog_product_attribute                Product EAV\ninventory                                Inventory\ncatalogrule_product                      Catalog Product Rule\ncataloginventory_stock                   Stock\ncatalog_product_price                    Product Price\ncatalogsearch_fulltext                   Catalog Search\n</code></pre>"},{"location":"snippets/magento-indexing/#view-indexer-status","title":"View indexer status","text":"<p>Use this command to view the status of all indexers or specific indexers. For example, find out if an indexer needs to be reindexed.</p> <pre><code>bin/magento indexer:status [indexer]\n</code></pre> <p>To list status of all indexers:</p> <pre><code>bin/magento indexer:status\n</code></pre>"},{"location":"snippets/magento-indexing/#to-reindex","title":"To Reindex","text":"<p>Use this command to reindex all or selected indexers one time only.</p> <pre><code>bin/magento indexer:reindex [indexer]\n</code></pre> <p>To reindex all indexers:</p> <pre><code>bin/magento indexer:reindex\n</code></pre> <p>To use multiple threads for indexing use:</p> <pre><code>MAGE_INDEXER_THREADS_COUNT=16 php -dmemory_limit=8G bin/magento indexer:reindex\n</code></pre>"},{"location":"snippets/magento-indexing/#reset-indexer","title":"Reset indexer","text":"<p>Use this command to invalidate the status of all indexers or specific indexers.</p> <pre><code>bin/magento indexer:reset [indexer]\n</code></pre> <p>To invalidate all indexers.</p> <pre><code>bin/magento indexer:reset\n</code></pre>"},{"location":"snippets/magento-indexing/#references","title":"References","text":"<ul> <li>https://devdocs.magento.com/guides/v2.3/extension-dev-guide/indexing.html</li> <li>https://devdocs.magento.com/guides/v2.3/config-guide/cli/config-cli-subcommands-index.html</li> </ul>"},{"location":"snippets/rsync-cloud-media/","title":"Rsync Media files in Magento Cloud","text":"<p>We may have to sync magento media files from one server to another in magento cloud.</p> <p>Magento cloud does not give us full permissions on their servers, we are left with restricted access.</p>"},{"location":"snippets/rsync-cloud-media/#warning","title":"Warning","text":"<p>Make necessary backups of the media files on the destination magento cloud server.</p> <pre><code>BKPTIM=$(date +\"%Y-%m-%d_%H-%M-%S\")\n</code></pre> <pre><code>TKT=\"JIRA-123\"\n</code></pre> <pre><code>cd pub/\ntar -zcf ../var/$TKT.media.backup.$BKPTIM.tar.gz media\n</code></pre>"},{"location":"snippets/rsync-cloud-media/#procedure","title":"Procedure","text":"<p>Create a temporary SSH key file on the source magento cloud server.</p> <p>Add the SSH Public key in magento cloud project portal under SSH Keys.</p> <p>Login to source magento cloud server and then run:</p> <pre><code>rsync -Pavz -e \"ssh -i var/path/to/private_key_rsa\" pub/media/* remote_ssh_user@remote.destination.server:/path/to/the/magento/pub/media/\n</code></pre>"},{"location":"snippets/suid-sandbox-helper-error-ubuntu/","title":"AppImage Error due to apparmor profiles","text":""},{"location":"snippets/suid-sandbox-helper-error-ubuntu/#the-suid-sandbox-helper-binary-was-found-but-is-not-configured-correctly","title":"The SUID sandbox helper binary was found, but is not configured correctly","text":"<p>For ex:</p> <p>Question?</p> <p>After upgrading to 24.04, I get the \"The SUID sandbox helper binary was found, but is not configured correctly.\" message when I try to run this Electron AppImage application file. The entire error looks like this (example for Obsidian app):</p> <p>Error excerpt:</p> <pre><code>&gt; ./Obsidian-1.4.13.AppImage\n\n\n[21824:0430/094557.661436:FATAL:setuid_sandbox_host.cc(158)]\nThe SUID sandbox helper binary was found, but is not configured correctly.\nRather than run without sandboxing I'm aborting now. You need to make sure that /tmp/.mount_ObsidiOpBPaM/chrome-sandbox is owned by root and has mode 4755.\nTrace/breakpoint trap (core dumped)\n</code></pre>"},{"location":"snippets/suid-sandbox-helper-error-ubuntu/#fix","title":"FIX","text":"<p>Probably the best way to solve the problem is to create an apparmor profile which allows the application to make use of unprivileged usernamespaces.</p> <p>Create the file named <code>/etc/apparmor.d/obsidianappimage</code> with the following content:</p> <pre><code># This profile allows everything and only exists to give the\n# application a name instead of having the label \"unconfined\"\n\nabi &lt;abi/4.0&gt;,\ninclude &lt;tunables/global&gt;\n\nprofile obsidianappimage /path/to/Obsidian-1.6.7.AppImage flags=(default_allow) {\n  userns,\n\n  # Site-specific additions and overrides. See local/README for details.\n  include if exists &lt;local/obsidianappimage&gt;\n}\n</code></pre> <p>Replace the <code>/path/to/Obsidian-1.6.7.AppImage</code> with the actual path to your appimage.</p> <p>After saving the file run the below command to reload all apparmor profiles:</p> <pre><code>sudo systemctl reload apparmor.service\n</code></pre> <p>If this command does not work for you, simply reboot.</p> <p>Do not move your AppImage file</p> <p>Note: Moving the appimage to a different location later or changing it's name makes it neccessary to update your apparmor profile with the correct path and reload the apparmor profiles.</p> <p>References : </p> <ul> <li>https://ubuntu.com/blog/ubuntu-23-10-restricted-unprivileged-user-namespaces</li> <li>https://askubuntu.com/questions/1512287/obsidian-appimage-the-suid-sandbox-helper-binary-was-found-but-is-not-configu</li> </ul>"}]}